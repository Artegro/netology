# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

  Ответ:
  - общая загрузка ЦП / Load Average - оценка нагрузки
  - Мониторинг сети -  подключение, её скорость и утилизацию
  - Состояние дисков - smart на предмет умирания дисков
  - Состояние рейда - что там с ним
  - Место на диске - отслеживаем скорость заполнение диска и расчитываем исходя из этого наши действия или очиска или апгрейд
  - Доступность HTTP порта нашего сервиса
  - И можно мониторить http запросы - сколько запросов, и коды
  
===============

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?

  Ответ:
  - Разъясним менеджеру понятия  RAM/inodes/CPUla, RAM - Состояние оперативной памяти, /  inodes - Загруженность файловой системы (грубо сколько еще файлов мы можем создать и записать данных) / CPUla - Средняя нагрузка на процессор и эти параметры показывают состояние системы и по их изменениям мы видим узкие меята в производительности, а так же прогназироуем необходимые маштабирования платформы. 
  - Но так как менеджер хочет понимать насколько выполняются обязательства перед клиентами и какое качество обслуживания, то стоит оговорить использование подхода (SLO, SLA, SLI). Так как у нас сервис работает по HTTP протоколу, то в нем будем использовать соотношение кодов отдаваемых нашим сервером  2хх и 3хх  ко всем остальным будет ниже установленного нами значения (например SLO = 99%, то SLA для клиентов мы устанавливаем немного ниже 98%), то это будет означать что качество обслуживания клиентов неудовлетровительное. Так же можем сделать подобный алгоритм на время прибывания запроса в очереди, то есть если у нас ростет среднее время прибывания запросов в очереди больше установленного значения, это говорит нам так же о ненадлежащем качестве обслуживании клиентов. 
  
 ===============

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

Ответ:
  - Первое что прихордит на ум, отправка логов в почту пока еще есть бесплатные сервисы типо mail.ru...  неудобно, криво, адское г .. но логи будут
  - Выкроить немного ресурсов из уже существующей инфраструктуры, оптимизация и ужимание... то же не панацея, мы обираем запас мощности с работающих сервисов, что не есть хорошо и не расчитано на долгое использование.
  - Перечисленные выше решения хороши только как временные перебиться пока не выделят средства на необходимые мощности.  
  
===============

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

summ_2xx_requests То, что у нас нет кодов 4** и 5** не говорить о том, что у на нет кодов 1** и 3**, а в формуле их нет, соответственно правильная формула будет 
  (summ_1xx_requests + summ_2xx_requests + summ_3xx_requests)/summ_all_requests
  
===============

5. Опишите основные плюсы и минусы pull и push систем мониторинга.

Ответ:
  ### Push ###
    Плюсы:
    - Возможность направлять данные в несколько таргетов
    - Работает за NAT
    - Мониторинг ноды без лишних алёртов, при нестабильной сеть и т.д.
    - Gри вводе ноды в эксплуатацию, нужно настроить только ноду, сервер настраивать не нужно
    
    Минусы:
    - Агенты могут перегрузить сервера запросами
    - Требует открытия порта сервера наружу, страдает безопасность
    - Могут приходить данные, которые нам не нужны, т.е. сервер не контролирует ничего: частоту отправки данных, объём и тд.

  ### Pull ###
    Плюсы:
    - Не трабует открытие порта сервера наружу
    - Сервер сам инициирует сбюор данных с агентов (нет переполнения ненужными данными)
    - Возможность получения только нужных данных с агентов
    Минусы:
    - Не работает на NAT
    - Больше накладных расходов по сети, так как отправку инициирует Сервер.
    
===============

6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus - рабюотает по Pull моделе
    - TICK - так же Pull
    - Zabbix - возможно использование гибридной модели Push & Pull (есть активные агенты но так же можем собирать данные с оборудования по SNMP наприер)
    - VictoriaMetrics -  так же Push & Pull в зависимости от истчника
    - Nagios - Pull
#

===============

7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

Копирует репозиторий:
```
git clone git@github.com:influxdata/sandbox.git
Cloning into 'sandbox'...
remote: Enumerating objects: 1718, done.
remote: Counting objects: 100% (32/32), done.
remote: Compressing objects: 100% (22/22), done.
remote: Total 1718 (delta 13), reused 25 (delta 10), pack-reused 1686
Receiving objects: 100% (1718/1718), 7.17 MiB | 4.50 MiB/s, done.
Resolving deltas: 100% (946/946), done.
```
Запускает
```
 ./sandbox up
Using latest, stable releases
Spinning up Docker Images...
...
Successfully built 1175a6237a67
Successfully tagged sandbox_documentation:latest
Creating sandbox_documentation_1 ... done
Creating sandbox_influxdb_1      ... done
Creating sandbox_telegraf_1      ... done
Creating sandbox_kapacitor_1     ... done
Creating sandbox_chronograf_1    ... done
Opening tabs in browser...
```

В виде решения на это упражнение приведите выводы команд с вашего компьютера (виртуальной машины):

    - curl http://localhost:8086/ping
    - curl http://localhost:8888
    - curl http://localhost:9092/kapacitor/v1/ping

Ну и вывод
```
root@test:/home/artegro/sandbox/sandbox# curl http://localhost:8086/ping
root@test:/home/artegro/sandbox/sandbox# curl http://localhost:8888
<!DOCTYPE html><html><head><link rel="stylesheet" href="/index.c708214f.css"><meta http-equiv="Content-type" content="text/html; charset=utf-8"><title>Chronograf</title><link rel="icon shortcut" href="/favicon.70d63073.ico"></head><body> <div id="react-root" data-basepath=""></div> <script type="module" src="/index.c5ba09e6.js"></script><script src="/index.59cbcbd2.js" nomodule="" defer></script> </body></html>root@test:/home/artegro/sandbox/sandbox# curl http://curl http://localhost:9092/kapacitor/v1/ping

```

А также скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

![image](https://user-images.githubusercontent.com/95859890/226823807-91300a0d-01c6-4326-b4a8-2275179bff8e.png)


P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#

===============

8. Перейдите в веб-интерфейс Chronograf (`http://localhost:8888`) и откройте вкладку `Data explorer`.

    - Нажмите на кнопку `Add a query`
    - Изучите вывод интерфейса и выберите БД `telegraf.autogen`
    - В `measurments` выберите mem->host->telegraf_container_id , а в `fields` выберите used_percent. 
    Внизу появится график утилизации оперативной памяти в контейнере telegraf.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. 
    Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации места на диске 
(disk->host->telegraf_container_id) из веб-интерфейса.

Добавим в конфиг 'telegraf.conf' поддержку 'mem' и 'disk' 
```
[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]
[[inputs.mem]]
```

![image](https://user-images.githubusercontent.com/95859890/226828946-64c7106f-0efd-4b01-8dd3-ff433f835560.png)

![image](https://user-images.githubusercontent.com/95859890/226829006-77d6d563-a570-49d8-88bf-4b6bb4891b29.png)
===============

9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

![image](https://user-images.githubusercontent.com/95859890/226837829-68a5b51f-f423-4b95-8fca-716fd601b37f.png)


Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

===============


## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

